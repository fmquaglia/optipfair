{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BXHrJ23DUwu"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/optipfair/blob/main/examples/bias_compatibility_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN0UvAbtDUwv"
      },
      "source": [
        "#OptiPFair Notebook Series ‚Äì Bias Visualization Compatibility Checker\n",
        "\n",
        "![optiPfair Logo](https://github.com/peremartra/optipfair/blob/main/images/optiPfair.png?raw=true)\n",
        "\n",
        "\n",
        "Verify if your model is compatible with [OptiPFair](https://github.com/peremartra/optipfair) bias visualization capabilities for analyzing fairness and bias in transformer models.\n",
        "\n",
        "This notebook quickly verifies if your transformer model is compatible with OptipFair's **bias visualization** capabilities.\n",
        "\n",
        "**In 30 seconds, you'll know:**\n",
        "- Can I analyze bias in this model with OptipFair?\n",
        "- What visualization types are supported?\n",
        "- Are all required dependencies available?\n",
        "- Any specific recommendations for my model?\n",
        "\n",
        "**Supported features:** Activation capture, mean difference plots, heatmaps, PCA analysis, and bias metrics.\n",
        "\n",
        "##Recommended Environment\n",
        "\n",
        "- **Platform**: [Google Colab](https://colab.research.google.com)  \n",
        "- **Hardware**: GPU runtime (recommended: T4 or better for 1B‚Äì3B models)  \n",
        "- **Dependencies**: Installed automatically in the first cell\n",
        "\n",
        "##by Pere Martra.\n",
        "\n",
        "- [LinkedIn](https://www.linkedin.com/in/pere-martra)  \n",
        "- [GitHub](https://github.com/peremartra)  \n",
        "- [X / Twitter](https://x.com/peremartra)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y9K3lIGDUww"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j0YwxH_DUww",
        "outputId": "b09d2a9a-89ca-4be3-ecf1-0308f80227b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages with bias visualization support\n",
        "!pip install \"optipfair[viz]\" -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4etUdnoDUwx",
        "outputId": "0de37904-ad27-457f-9382-8a8763fa057e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup complete!\n",
            "üî• PyTorch version: 2.6.0+cu124\n",
            "ü§ó Device: GPU\n",
            "üì¶ OptipFair bias visualization compatibility checker ready\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"ü§ó Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(\"üì¶ OptipFair bias visualization compatibility checker ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCvJB5gHDUwx"
      },
      "source": [
        "## Model Input\n",
        "**Enter your model name below:**  \n",
        "You can use any Hugging Face model ID (e.g., `meta-llama/Llama-3.2-1B`, `google/gemma-2-2b`)\n",
        "\n",
        "Tested with: meta-llama/Llama-3.2-1B, google/gemma-2-2b, google/gemma-3-270m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hhfvSZJDUwx",
        "outputId": "c011291c-ce51-42b7-c01b-afd76d953a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Checking bias visualization compatibility for: google/gemma-3-270m\n"
          ]
        }
      ],
      "source": [
        "# üëá EDIT THIS: Enter your model name\n",
        "MODEL_NAME = \"google/gemma-3-270m\"  # Change this to test your model\n",
        "print(f\"üîç Checking bias visualization compatibility for: {MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rd4RHepDUwx"
      },
      "source": [
        "## Compatibility Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD3pkCw7DUwy"
      },
      "outputs": [],
      "source": [
        "def check_dependencies():\n",
        "    \"\"\"\n",
        "    Check if all required dependencies are available for bias visualization\n",
        "    \"\"\"\n",
        "    dependencies = {\n",
        "        \"matplotlib\": False,\n",
        "        \"seaborn\": False,\n",
        "        \"sklearn\": False,\n",
        "        \"numpy\": False,\n",
        "        \"optipfair_bias\": False,\n",
        "        \"all_available\": False\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        dependencies[\"matplotlib\"] = True\n",
        "\n",
        "        import seaborn as sns\n",
        "        dependencies[\"seaborn\"] = True\n",
        "\n",
        "        import sklearn\n",
        "        from sklearn.decomposition import PCA\n",
        "        dependencies[\"sklearn\"] = True\n",
        "\n",
        "        import numpy as np\n",
        "        dependencies[\"numpy\"] = True\n",
        "\n",
        "        # Test OptiPFair bias module\n",
        "        from optipfair.bias import visualize_bias\n",
        "        dependencies[\"optipfair_bias\"] = True\n",
        "\n",
        "        dependencies[\"all_available\"] = all([\n",
        "            dependencies[\"matplotlib\"],\n",
        "            dependencies[\"seaborn\"],\n",
        "            dependencies[\"sklearn\"],\n",
        "            dependencies[\"numpy\"],\n",
        "            dependencies[\"optipfair_bias\"]\n",
        "        ])\n",
        "\n",
        "        return dependencies\n",
        "\n",
        "    except ImportError as e:\n",
        "        dependencies[\"error\"] = str(e)\n",
        "        return dependencies\n",
        "\n",
        "def check_model_architecture(model_name):\n",
        "    \"\"\"\n",
        "    Check if model has the required architecture for bias visualization\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"üîÑ Loading model configuration...\")\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "        # Initialize results\n",
        "        results = {\n",
        "            \"model_name\": model_name,\n",
        "            \"config_loaded\": True,\n",
        "            \"architecture_compatible\": False,\n",
        "            \"issues\": [],\n",
        "            \"recommendations\": [],\n",
        "            \"details\": {}\n",
        "        }\n",
        "\n",
        "        # Extract basic info\n",
        "        results[\"details\"][\"model_type\"] = getattr(config, 'model_type', 'Unknown')\n",
        "        results[\"details\"][\"num_layers\"] = getattr(config, 'num_hidden_layers', 'N/A')\n",
        "        results[\"details\"][\"hidden_size\"] = getattr(config, 'hidden_size', 'N/A')\n",
        "        results[\"details\"][\"intermediate_size\"] = getattr(config, 'intermediate_size', 'N/A')\n",
        "\n",
        "        print(f\"üìä Model type: {results['details']['model_type']}\")\n",
        "        print(f\"üìä Layers: {results['details']['num_layers']}\")\n",
        "        print(f\"üìä Hidden size: {results['details']['hidden_size']}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "        return {\n",
        "            \"model_name\": model_name,\n",
        "            \"config_loaded\": False,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def test_hook_registration(model_name):\n",
        "    \"\"\"\n",
        "    Test if we can register hooks and capture activations for bias visualization.\n",
        "    Based on OptiPFair's bias module requirements.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"\\nüîç Testing hook registration and activation capture...\")\n",
        "\n",
        "        # Load a small portion of the model\n",
        "        model = AutoModel.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\" if torch.cuda.is_available() else \"cpu\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Try to find the model layers - OptiPFair expects model.model.layers structure\n",
        "        layers = None\n",
        "        layer_access_method = None\n",
        "\n",
        "        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
        "            layers = model.model.layers\n",
        "            layer_access_method = \"model.model.layers\"\n",
        "        elif hasattr(model, 'layers'):\n",
        "            layers = model.layers\n",
        "            layer_access_method = \"model.layers\"\n",
        "        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
        "            layers = model.transformer.h\n",
        "            layer_access_method = \"model.transformer.h\"\n",
        "\n",
        "        if layers is None or len(layers) == 0:\n",
        "            return {\n",
        "                \"hook_registration\": False,\n",
        "                \"layers_found\": False,\n",
        "                \"error\": \"Could not find transformer layers\"\n",
        "            }\n",
        "\n",
        "        # Test hook registration on first layer\n",
        "        first_layer = layers[0]\n",
        "        hook_results = {\n",
        "            \"layers_found\": True,\n",
        "            \"layer_access_method\": layer_access_method,\n",
        "            \"total_layers\": len(layers),\n",
        "            \"components_found\": {},\n",
        "            \"supported_visualizations\": [],\n",
        "            \"layer_types_available\": []\n",
        "        }\n",
        "\n",
        "        # Test for attention component (generates attention_output_layer_N)\n",
        "        if hasattr(first_layer, 'self_attn'):\n",
        "            hook_results[\"components_found\"][\"attention\"] = True\n",
        "            hook_results[\"components_found\"][\"attention_type\"] = \"self_attn\"\n",
        "            hook_results[\"layer_types_available\"].append(\"attention_output\")\n",
        "            hook_results[\"supported_visualizations\"].extend([\n",
        "                \"attention_output: mean_diff visualizations\",\n",
        "                \"attention_output: heatmap visualizations\",\n",
        "                \"attention_output: PCA analysis\"\n",
        "            ])\n",
        "        elif hasattr(first_layer, 'attn'):\n",
        "            hook_results[\"components_found\"][\"attention\"] = True\n",
        "            hook_results[\"components_found\"][\"attention_type\"] = \"attn\"\n",
        "            hook_results[\"layer_types_available\"].append(\"attention_output\")\n",
        "            hook_results[\"supported_visualizations\"].extend([\n",
        "                \"attention_output: mean_diff visualizations\",\n",
        "                \"attention_output: heatmap visualizations\",\n",
        "                \"attention_output: PCA analysis\"\n",
        "            ])\n",
        "        else:\n",
        "            hook_results[\"components_found\"][\"attention\"] = False\n",
        "            hook_results[\"components_found\"][\"attention_type\"] = None\n",
        "\n",
        "        # Test for MLP component (generates mlp_output_layer_N)\n",
        "        if hasattr(first_layer, 'mlp'):\n",
        "            hook_results[\"components_found\"][\"mlp\"] = True\n",
        "            hook_results[\"layer_types_available\"].append(\"mlp_output\")\n",
        "            mlp = first_layer.mlp\n",
        "\n",
        "            # Check for GLU components (important for detailed MLP analysis)\n",
        "            if hasattr(mlp, 'gate_proj'):\n",
        "                hook_results[\"components_found\"][\"gate_proj\"] = True\n",
        "                hook_results[\"layer_types_available\"].append(\"gate_proj\")\n",
        "                hook_results[\"supported_visualizations\"].extend([\n",
        "                    \"gate_proj: mean_diff visualizations\",\n",
        "                    \"gate_proj: heatmap visualizations\"\n",
        "                ])\n",
        "\n",
        "            if hasattr(mlp, 'up_proj'):\n",
        "                hook_results[\"components_found\"][\"up_proj\"] = True\n",
        "                hook_results[\"layer_types_available\"].append(\"up_proj\")\n",
        "                hook_results[\"supported_visualizations\"].extend([\n",
        "                    \"up_proj: mean_diff visualizations\",\n",
        "                    \"up_proj: heatmap visualizations\"\n",
        "                ])\n",
        "\n",
        "            if hasattr(mlp, 'down_proj'):\n",
        "                hook_results[\"components_found\"][\"down_proj\"] = True\n",
        "                hook_results[\"layer_types_available\"].append(\"down_proj\")\n",
        "\n",
        "            # Add MLP visualizations (PCA only for mlp_output, not individual projections)\n",
        "            hook_results[\"supported_visualizations\"].extend([\n",
        "                \"mlp_output: mean_diff visualizations\",\n",
        "                \"mlp_output: heatmap visualizations\",\n",
        "                \"mlp_output: PCA analysis\"\n",
        "            ])\n",
        "        else:\n",
        "            hook_results[\"components_found\"][\"mlp\"] = False\n",
        "\n",
        "        # Test for input normalization (generates input_norm_layer_N)\n",
        "        if hasattr(first_layer, 'input_layernorm'):\n",
        "            hook_results[\"components_found\"][\"input_norm\"] = True\n",
        "            hook_results[\"layer_types_available\"].append(\"input_norm\")\n",
        "\n",
        "        # Test actual hook registration\n",
        "        test_activations = {}\n",
        "\n",
        "        def test_hook(name):\n",
        "            def hook(module, input, output):\n",
        "                if isinstance(output, tuple):\n",
        "                    test_activations[name] = output[0].detach().cpu()\n",
        "                else:\n",
        "                    test_activations[name] = output.detach().cpu()\n",
        "            return hook\n",
        "\n",
        "        # Register test hooks\n",
        "        handles = []\n",
        "        if hook_results[\"components_found\"][\"attention\"]:\n",
        "            if hasattr(first_layer, 'self_attn'):\n",
        "                handles.append(first_layer.self_attn.register_forward_hook(test_hook(\"test_attention\")))\n",
        "            elif hasattr(first_layer, 'attn'):\n",
        "                handles.append(first_layer.attn.register_forward_hook(test_hook(\"test_attention\")))\n",
        "\n",
        "        if hook_results[\"components_found\"][\"mlp\"]:\n",
        "            handles.append(first_layer.mlp.register_forward_hook(test_hook(\"test_mlp\")))\n",
        "\n",
        "        hook_results[\"hook_registration\"] = len(handles) > 0\n",
        "\n",
        "        # Clean up\n",
        "        for handle in handles:\n",
        "            handle.remove()\n",
        "\n",
        "        del model\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return hook_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Hook registration test failed: {str(e)}\")\n",
        "        return {\n",
        "            \"hook_registration\": False,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def test_tokenizer_compatibility(model_name):\n",
        "    \"\"\"\n",
        "    Test if tokenizer works properly for bias analysis\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"\\nüîç Testing tokenizer compatibility...\")\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # Test tokenization with sample bias analysis prompts from OptiPFair defaults\n",
        "        test_prompts = [\n",
        "            \"The white man walked through the neighborhood. The police officer thought he\",\n",
        "            \"The Black man walked through the neighborhood. The police officer thought he\",\n",
        "            \"The male engineer proposed a solution. The team thought it was\",\n",
        "            \"The female engineer proposed a solution. The team thought it was\"\n",
        "        ]\n",
        "\n",
        "        tokenizer_results = {\n",
        "            \"tokenizer_loaded\": True,\n",
        "            \"pad_token_available\": tokenizer.pad_token is not None,\n",
        "            \"can_tokenize\": True,\n",
        "            \"tokenization_examples\": []\n",
        "        }\n",
        "\n",
        "        # Test tokenization\n",
        "        for prompt in test_prompts:\n",
        "            try:\n",
        "                tokens = tokenizer.tokenize(prompt)\n",
        "                if len(tokens) == 0:\n",
        "                    tokenizer_results[\"can_tokenize\"] = False\n",
        "                    break\n",
        "                tokenizer_results[\"tokenization_examples\"].append({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"tokens\": len(tokens),\n",
        "                    \"success\": True\n",
        "                })\n",
        "            except Exception as e:\n",
        "                tokenizer_results[\"can_tokenize\"] = False\n",
        "                tokenizer_results[\"tokenization_examples\"].append({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"error\": str(e),\n",
        "                    \"success\": False\n",
        "                })\n",
        "                break\n",
        "\n",
        "        return tokenizer_results\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"tokenizer_loaded\": False,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# Run all compatibility checks\n",
        "print(\"Starting compatibility analysis...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check dependencies\n",
        "print(\"üì¶ Checking bias visualization dependencies...\")\n",
        "dep_results = check_dependencies()\n",
        "\n",
        "# Check model architecture\n",
        "arch_results = check_model_architecture(MODEL_NAME)\n",
        "\n",
        "# Test hook registration\n",
        "hook_results = test_hook_registration(MODEL_NAME)\n",
        "\n",
        "# Test tokenizer\n",
        "tokenizer_results = test_tokenizer_compatibility(MODEL_NAME)\n",
        "\n",
        "print(\"\\n‚úÖ Compatibility analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w19g8XFPDUwy"
      },
      "outputs": [],
      "source": [
        "def generate_compatibility_assessment(dep_results, arch_results, hook_results, tokenizer_results):\n",
        "    \"\"\"\n",
        "    Generate final compatibility assessment\n",
        "    \"\"\"\n",
        "    assessment = {\n",
        "        \"model_name\": arch_results.get(\"model_name\", \"Unknown\"),\n",
        "        \"compatible\": False,\n",
        "        \"compatibility_score\": 0,\n",
        "        \"supported_features\": [],\n",
        "        \"issues\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"details\": {}\n",
        "    }\n",
        "\n",
        "    # Check dependencies\n",
        "    if dep_results.get(\"all_available\", False):\n",
        "        assessment[\"compatibility_score\"] += 25\n",
        "        assessment[\"supported_features\"].append(\"‚úÖ All visualization dependencies available\")\n",
        "    else:\n",
        "        assessment[\"issues\"].append(\"‚ùå Missing visualization dependencies\")\n",
        "\n",
        "    # Check model architecture\n",
        "    if arch_results.get(\"config_loaded\", False):\n",
        "        assessment[\"compatibility_score\"] += 25\n",
        "        assessment[\"supported_features\"].append(\"‚úÖ Model configuration loaded successfully\")\n",
        "\n",
        "        # Check for supported model types\n",
        "        model_type = arch_results.get(\"details\", {}).get(\"model_type\", \"\").lower()\n",
        "        supported_types = [\"llama\", \"mistral\", \"gemma\", \"qwen\", \"phi\"]\n",
        "\n",
        "        if any(supported_type in model_type for supported_type in supported_types):\n",
        "            assessment[\"supported_features\"].append(f\"‚úÖ Supported architecture: {model_type}\")\n",
        "        else:\n",
        "            assessment[\"issues\"].append(f\"‚ö†Ô∏è  Architecture '{model_type}' may have limited support\")\n",
        "    else:\n",
        "        assessment[\"issues\"].append(\"‚ùå Could not load model configuration\")\n",
        "\n",
        "    # Check hook registration\n",
        "    if hook_results.get(\"hook_registration\", False):\n",
        "        assessment[\"compatibility_score\"] += 30\n",
        "        assessment[\"supported_features\"].append(\"‚úÖ Hook registration successful\")\n",
        "\n",
        "        # Check specific components\n",
        "        components = hook_results.get(\"components_found\", {})\n",
        "        if components.get(\"attention\", False):\n",
        "            assessment[\"supported_features\"].append(\"‚úÖ Attention components available\")\n",
        "        if components.get(\"mlp\", False):\n",
        "            assessment[\"supported_features\"].append(\"‚úÖ MLP components available\")\n",
        "        if components.get(\"gate_proj\", False) and components.get(\"up_proj\", False):\n",
        "            assessment[\"supported_features\"].append(\"‚úÖ GLU components available\")\n",
        "    else:\n",
        "        assessment[\"issues\"].append(\"‚ùå Hook registration failed\")\n",
        "\n",
        "    # Check tokenizer\n",
        "    if tokenizer_results.get(\"tokenizer_loaded\", False):\n",
        "        assessment[\"compatibility_score\"] += 20\n",
        "        assessment[\"supported_features\"].append(\"‚úÖ Tokenizer loaded successfully\")\n",
        "\n",
        "        if tokenizer_results.get(\"can_tokenize\", False):\n",
        "            assessment[\"supported_features\"].append(\"‚úÖ Tokenization working\")\n",
        "    else:\n",
        "        assessment[\"issues\"].append(\"‚ùå Tokenizer loading failed\")\n",
        "\n",
        "    # Overall compatibility\n",
        "    assessment[\"compatible\"] = assessment[\"compatibility_score\"] >= 70\n",
        "\n",
        "    # Generate recommendations\n",
        "    if assessment[\"compatible\"]:\n",
        "        assessment[\"recommendations\"] = [\n",
        "            \"üéâ Your model is compatible with OptiPFair bias visualization!\",\n",
        "            \"üì¶ Install: pip install optipfair\",\n",
        "            \"üìì Try the basic_bias_visualization.ipynb example\",\n",
        "            \"üîó Documentation: https://github.com/peremartra/optipfair\"\n",
        "        ]\n",
        "    else:\n",
        "        assessment[\"recommendations\"] = [\n",
        "            \"‚ö†Ô∏è  Your model may have limited compatibility\",\n",
        "            \"üìß Report issues: https://github.com/peremartra/optipfair/issues\",\n",
        "            \"üìö Check supported models in documentation\"\n",
        "        ]\n",
        "\n",
        "    # Store detailed results\n",
        "    assessment[\"details\"] = {\n",
        "        \"dependencies\": dep_results,\n",
        "        \"architecture\": arch_results,\n",
        "        \"hooks\": hook_results,\n",
        "        \"tokenizer\": tokenizer_results\n",
        "    }\n",
        "\n",
        "    return assessment\n",
        "\n",
        "# Generate final assessment\n",
        "final_assessment = generate_compatibility_assessment(dep_results, arch_results, hook_results, tokenizer_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxA1IM1aDUwy"
      },
      "source": [
        "## Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6eZ0tGtDUwy",
        "outputId": "382e7eab-f949-42d3-f8ca-15f9d0aa1c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üéØ OPTIPFAIR BIAS VISUALIZATION COMPATIBILITY REPORT\n",
            "============================================================\n",
            "\n",
            "‚úÖ STATUS: COMPATIBLE\n",
            "üìä COMPATIBILITY SCORE: 100/100\n",
            "üì¶ MODEL: google/gemma-3-270m\n",
            "\n",
            "‚úÖ SUPPORTED FEATURES:\n",
            "   ‚úÖ All visualization dependencies available\n",
            "   ‚úÖ Model configuration loaded successfully\n",
            "   ‚úÖ Supported architecture: gemma3_text\n",
            "   ‚úÖ Hook registration successful\n",
            "   ‚úÖ Attention components available\n",
            "   ‚úÖ MLP components available\n",
            "   ‚úÖ GLU components available\n",
            "   ‚úÖ Tokenizer loaded successfully\n",
            "   ‚úÖ Tokenization working\n",
            "\n",
            "üé® AVAILABLE VISUALIZATIONS:\n",
            "   üìä VISUALIZATION TYPES:\n",
            "   üîç MEAN DIFFERENCE PLOTS:\n",
            "      ‚Ä¢ attention_output_layer_N visualizations\n",
            "      ‚Ä¢ mlp_output_layer_N visualizations\n",
            "      ‚Ä¢ gate_proj_layer_N visualizations\n",
            "      ‚Ä¢ up_proj_layer_N visualizations\n",
            "   üî• HEATMAP VISUALIZATIONS:\n",
            "      ‚Ä¢ attention_output_layer_N heatmaps\n",
            "      ‚Ä¢ mlp_output_layer_N heatmaps\n",
            "      ‚Ä¢ gate_proj_layer_N heatmaps\n",
            "      ‚Ä¢ up_proj_layer_N heatmaps\n",
            "   üìà PCA ANALYSIS:\n",
            "      ‚Ä¢ attention_output_layer_N PCA plots\n",
            "      ‚Ä¢ mlp_output_layer_N PCA plots\n",
            "   üìä BIAS METRICS:\n",
            "      ‚Ä¢ Quantitative bias measurements\n",
            "      ‚Ä¢ Cross-layer activation comparisons\n",
            "      ‚Ä¢ Statistical significance tests\n",
            "      ‚Ä¢ Layer-wise progression analysis\n",
            "\n",
            "üîç DETECTED LAYER CAPABILITIES:\n",
            "   ‚úÖ attention_output: mean_diff visualizations\n",
            "   ‚úÖ attention_output: heatmap visualizations\n",
            "   ‚úÖ attention_output: PCA analysis\n",
            "   ‚úÖ gate_proj: mean_diff visualizations\n",
            "   ‚úÖ gate_proj: heatmap visualizations\n",
            "   ‚úÖ up_proj: mean_diff visualizations\n",
            "   ‚úÖ up_proj: heatmap visualizations\n",
            "   ‚úÖ mlp_output: mean_diff visualizations\n",
            "   ‚úÖ mlp_output: heatmap visualizations\n",
            "   ‚úÖ mlp_output: PCA analysis\n",
            "\n",
            "üèóÔ∏è  AVAILABLE LAYER TYPES:\n",
            "   ‚Ä¢ attention_output_layer_N (N = 0 to 17)\n",
            "   ‚Ä¢ mlp_output_layer_N (N = 0 to 17)\n",
            "   ‚Ä¢ gate_proj_layer_N (N = 0 to 17)\n",
            "   ‚Ä¢ up_proj_layer_N (N = 0 to 17)\n",
            "   ‚Ä¢ down_proj_layer_N (N = 0 to 17)\n",
            "   ‚Ä¢ input_norm_layer_N (N = 0 to 17)\n",
            "\n",
            "üí° RECOMMENDATIONS:\n",
            "   üéâ Your model is compatible with OptiPFair bias visualization!\n",
            "   üì¶ Install: pip install optipfair\n",
            "   üìì Try the basic_bias_visualization.ipynb example\n",
            "   üîó Documentation: https://github.com/peremartra/optipfair\n",
            "\n",
            "üîß TECHNICAL DETAILS:\n",
            "   ‚Ä¢ Model Type: gemma3_text\n",
            "   ‚Ä¢ Layers: 18\n",
            "   ‚Ä¢ Hidden Size: 640\n",
            "   ‚Ä¢ Layer Access: model.layers\n",
            "   ‚Ä¢ Total Layers: 18\n",
            "   ‚Ä¢ Attention Component: ‚úÖ\n",
            "   ‚Ä¢ MLP Component: ‚úÖ\n",
            "   ‚Ä¢ GLU Architecture: ‚úÖ\n",
            "   ‚Ä¢ Gate Projection: ‚úÖ\n",
            "   ‚Ä¢ Up Projection: ‚úÖ\n",
            "   ‚Ä¢ Down Projection: ‚úÖ\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def display_compatibility_results(assessment):\n",
        "    \"\"\"\n",
        "    Display the final compatibility results in a clean format\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üéØ OPTIPFAIR BIAS VISUALIZATION COMPATIBILITY REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Header\n",
        "    status_emoji = \"‚úÖ\" if assessment[\"compatible\"] else \"‚ùå\"\n",
        "    status_text = \"COMPATIBLE\" if assessment[\"compatible\"] else \"LIMITED COMPATIBILITY\"\n",
        "\n",
        "    print(f\"\\n{status_emoji} STATUS: {status_text}\")\n",
        "    print(f\"üìä COMPATIBILITY SCORE: {assessment['compatibility_score']}/100\")\n",
        "    print(f\"üì¶ MODEL: {assessment['model_name']}\")\n",
        "\n",
        "    # Supported features\n",
        "    if assessment[\"supported_features\"]:\n",
        "        print(f\"\\n‚úÖ SUPPORTED FEATURES:\")\n",
        "        for feature in assessment[\"supported_features\"]:\n",
        "            print(f\"   {feature}\")\n",
        "\n",
        "    # Issues\n",
        "    if assessment[\"issues\"]:\n",
        "        print(f\"\\n‚ö†Ô∏è  ISSUES FOUND:\")\n",
        "        for issue in assessment[\"issues\"]:\n",
        "            print(f\"   {issue}\")\n",
        "\n",
        "    # Available visualizations - Enhanced with OptiPFair manual information\n",
        "    print(f\"\\nüé® AVAILABLE VISUALIZATIONS:\")\n",
        "    if assessment[\"compatible\"]:\n",
        "        hook_details = assessment[\"details\"].get(\"hooks\", {})\n",
        "        components = hook_details.get(\"components_found\", {})\n",
        "        layer_types = hook_details.get(\"layer_types_available\", [])\n",
        "\n",
        "        print(f\"   üìä VISUALIZATION TYPES:\")\n",
        "\n",
        "        # Mean difference plots\n",
        "        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]):\n",
        "            print(f\"   üîç MEAN DIFFERENCE PLOTS:\")\n",
        "            for layer_type in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]:\n",
        "                if layer_type in layer_types:\n",
        "                    print(f\"      ‚Ä¢ {layer_type}_layer_N visualizations\")\n",
        "\n",
        "        # Heatmap visualizations\n",
        "        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]):\n",
        "            print(f\"   üî• HEATMAP VISUALIZATIONS:\")\n",
        "            for layer_type in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]:\n",
        "                if layer_type in layer_types:\n",
        "                    print(f\"      ‚Ä¢ {layer_type}_layer_N heatmaps\")\n",
        "\n",
        "        # PCA analysis (only for attention_output and mlp_output)\n",
        "        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\"]):\n",
        "            print(f\"   üìà PCA ANALYSIS:\")\n",
        "            for layer_type in [\"attention_output\", \"mlp_output\"]:\n",
        "                if layer_type in layer_types:\n",
        "                    print(f\"      ‚Ä¢ {layer_type}_layer_N PCA plots\")\n",
        "\n",
        "        print(f\"   üìä BIAS METRICS:\")\n",
        "        print(f\"      ‚Ä¢ Quantitative bias measurements\")\n",
        "        print(f\"      ‚Ä¢ Cross-layer activation comparisons\")\n",
        "        print(f\"      ‚Ä¢ Statistical significance tests\")\n",
        "        print(f\"      ‚Ä¢ Layer-wise progression analysis\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  Limited or no visualization support\")\n",
        "\n",
        "    # Layer-specific capabilities based on OptiPFair documentation\n",
        "    hook_details = assessment[\"details\"].get(\"hooks\", {})\n",
        "    if hook_details.get(\"supported_visualizations\"):\n",
        "        print(f\"\\nüîç DETECTED LAYER CAPABILITIES:\")\n",
        "        for viz in hook_details[\"supported_visualizations\"]:\n",
        "            print(f\"   ‚úÖ {viz}\")\n",
        "\n",
        "    # Layer types available\n",
        "    if hook_details.get(\"layer_types_available\"):\n",
        "        print(f\"\\nüèóÔ∏è  AVAILABLE LAYER TYPES:\")\n",
        "        for layer_type in hook_details[\"layer_types_available\"]:\n",
        "            print(f\"   ‚Ä¢ {layer_type}_layer_N (N = 0 to {hook_details.get('total_layers', 'unknown')-1})\")\n",
        "\n",
        "    # Recommendations\n",
        "    if assessment[\"recommendations\"]:\n",
        "        print(f\"\\nüí° RECOMMENDATIONS:\")\n",
        "        for rec in assessment[\"recommendations\"]:\n",
        "            print(f\"   {rec}\")\n",
        "\n",
        "    # Technical details\n",
        "    arch_details = assessment[\"details\"].get(\"architecture\", {}).get(\"details\", {})\n",
        "    if arch_details:\n",
        "        print(f\"\\nüîß TECHNICAL DETAILS:\")\n",
        "        print(f\"   ‚Ä¢ Model Type: {arch_details.get('model_type', 'unknown')}\")\n",
        "        print(f\"   ‚Ä¢ Layers: {arch_details.get('num_layers', 'unknown')}\")\n",
        "        print(f\"   ‚Ä¢ Hidden Size: {arch_details.get('hidden_size', 'unknown')}\")\n",
        "\n",
        "    hook_details = assessment[\"details\"].get(\"hooks\", {})\n",
        "    if hook_details.get(\"layers_found\"):\n",
        "        print(f\"   ‚Ä¢ Layer Access: {hook_details.get('layer_access_method', 'unknown')}\")\n",
        "        print(f\"   ‚Ä¢ Total Layers: {hook_details.get('total_layers', 'unknown')}\")\n",
        "\n",
        "        # Component availability\n",
        "        components = hook_details.get(\"components_found\", {})\n",
        "        print(f\"   ‚Ä¢ Attention Component: {'‚úÖ' if components.get('attention') else '‚ùå'}\")\n",
        "        print(f\"   ‚Ä¢ MLP Component: {'‚úÖ' if components.get('mlp') else '‚ùå'}\")\n",
        "        if components.get('mlp'):\n",
        "            print(f\"   ‚Ä¢ GLU Architecture: {'‚úÖ' if components.get('gate_proj') and components.get('up_proj') else '‚ùå'}\")\n",
        "            print(f\"   ‚Ä¢ Gate Projection: {'‚úÖ' if components.get('gate_proj') else '‚ùå'}\")\n",
        "            print(f\"   ‚Ä¢ Up Projection: {'‚úÖ' if components.get('up_proj') else '‚ùå'}\")\n",
        "            print(f\"   ‚Ä¢ Down Projection: {'‚úÖ' if components.get('down_proj') else '‚ùå'}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Display final results\n",
        "display_compatibility_results(final_assessment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOrMep7FDUwz"
      },
      "source": [
        "## üîó What's Next?\n",
        "\n",
        "### ‚úÖ If your model is compatible:\n",
        "- **Install OptiPFair with bias visualization support:**\n",
        "  ```bash\n",
        "  pip install \"optipfair[viz]\"\n",
        "  ```\n",
        "- **Try basic bias visualization:**\n",
        "  ```python\n",
        "  from optipfair.bias import visualize_bias\n",
        "  # Use default prompt pairs or create custom ones\n",
        "  visualize_bias(model, tokenizer, output_dir=\"./bias_analysis\")\n",
        "  ```\n",
        "- **Explore specific visualizations:**\n",
        "  - `visualize_mean_differences()` for layer-wise analysis\n",
        "  - `visualize_heatmap()` for detailed activation patterns\n",
        "  - `visualize_pca()` for dimensional reduction analysis\n",
        "- **Custom analysis:** Create prompt pairs for your specific bias concerns\n",
        "\n",
        "### ‚ùå If your model has limited compatibility:\n",
        "- **Check layer structure:** Your model may need `model.model.layers` structure\n",
        "- **Request support:** Open an issue on [GitHub](https://github.com/peremartra/optipfair/issues)\n",
        "- **Try alternatives:** Use a supported model (LLaMA, Mistral, Gemma, Qwen, Phi) for testing\n",
        "- **Contribute:** Help us add support for your model architecture!\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learn More About OptiPFair Bias Visualization\n",
        "\n",
        "### üéØ **Key Features:**\n",
        "- **Layer Types Analyzed:** `attention_output`, `mlp_output`, `gate_proj`, `up_proj`, `down_proj`\n",
        "- **Visualization Types:** Mean differences, heatmaps, PCA analysis\n",
        "- **Metrics:** Quantitative bias measurements with statistical analysis\n",
        "- **Layer Selection:** `\"first_middle_last\"`, `\"all\"`, or specific indices\n",
        "\n",
        "### üìñ **Resources:**\n",
        "- **üìñ Documentation:** [OptipFair GitHub](https://github.com/peremartra/optipfair)  \n",
        "- **üìù LLM Reference Manual:** `optipfair_llm_reference_manual.txt` for detailed API info\n",
        "- **üéì Examples:** Check out the `examples/` directory for tutorials\n",
        "- **üî¨ Research:** \"From Biased to Balanced: Visualizing and Fixing Bias in Transformer Models\"\n",
        "\n",
        "### üõ†Ô∏è **Example Usage:**\n",
        "```python\n",
        "# Basic usage\n",
        "from optipfair.bias import visualize_bias\n",
        "_, metrics = visualize_bias(\n",
        "    model, tokenizer,\n",
        "    visualization_types=[\"mean_diff\", \"heatmap\", \"pca\"],\n",
        "    layers=\"first_middle_last\"\n",
        ")\n",
        "\n",
        "# Advanced - target specific layers\n",
        "from optipfair.bias import visualize_pca\n",
        "visualize_pca(\n",
        "    model, tokenizer,\n",
        "    prompt_pair=(\"The white doctor...\", \"The Black doctor...\"),\n",
        "    layer_key=\"attention_output_layer_8\"  # Specific layer\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "If you found this notebook useful, the best way to support the OptiPFair project is by **starring it on GitHub**. Your support helps boost the project's visibility and reach more developers and researchers.\n",
        "\n",
        "### ‚û°Ô∏è [**Star OptiPFair on GitHub**](https://github.com/peremartra/optipfair)\n",
        "\n",
        "---\n",
        "You can also follow my work and new projects on:\n",
        "\n",
        "* **[LinkedIn](https://www.linkedin.com/in/pere-martra/)**\n",
        "* **[X / Twitter](https://twitter.com/PereMartra)**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}