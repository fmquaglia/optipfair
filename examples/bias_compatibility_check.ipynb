{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/peremartra/optipfair/blob/main/examples/bias_compatibility_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#OptiPFair Notebook Series ‚Äì Bias Visualization Compatibility Checker\n",
    "\n",
    "![optiPfair Logo](https://github.com/peremartra/optipfair/blob/main/images/optiPfair.png?raw=true)\n",
    "\n",
    "\n",
    "Verify if your model is compatible with [OptiPFair](https://github.com/peremartra/optipfair) bias visualization capabilities for analyzing fairness and bias in transformer models.\n",
    "\n",
    "This notebook quickly verifies if your transformer model is compatible with OptipFair's **bias visualization** capabilities.\n",
    "\n",
    "**In 30 seconds, you'll know:**\n",
    "- Can I analyze bias in this model with OptipFair?\n",
    "- What visualization types are supported?\n",
    "- Are all required dependencies available?\n",
    "- Any specific recommendations for my model?\n",
    "\n",
    "**Supported features:** Activation capture, mean difference plots, heatmaps, PCA analysis, and bias metrics.\n",
    "\n",
    "##Recommended Environment\n",
    "\n",
    "- **Platform**: [Google Colab](https://colab.research.google.com)  \n",
    "- **Hardware**: GPU runtime (recommended: T4 or better for 1B‚Äì3B models)  \n",
    "- **Dependencies**: Installed automatically in the first cell\n",
    "\n",
    "##by Pere Martra.\n",
    "\n",
    "- [LinkedIn](https://www.linkedin.com/in/pere-martra)  \n",
    "- [GitHub](https://github.com/peremartra)  \n",
    "- [X / Twitter](https://x.com/peremartra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages with bias visualization support\n!pip install \"optipfair[viz]\" -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ó Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"üì¶ OptipFair bias visualization compatibility checker ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Input\n",
    "**Enter your model name below:**  \n",
    "You can use any Hugging Face model ID (e.g., `meta-llama/Llama-3.2-1B`, `google/gemma-2-2b`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëá EDIT THIS: Enter your model name\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"  # Change this to test your model\n",
    "print(f\"üîç Checking bias visualization compatibility for: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatibility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def check_dependencies():\n    \"\"\"\n    Check if all required dependencies are available for bias visualization\n    \"\"\"\n    dependencies = {\n        \"matplotlib\": False,\n        \"seaborn\": False,\n        \"sklearn\": False,\n        \"numpy\": False,\n        \"optipfair_bias\": False,\n        \"all_available\": False\n    }\n    \n    try:\n        import matplotlib.pyplot as plt\n        dependencies[\"matplotlib\"] = True\n        \n        import seaborn as sns\n        dependencies[\"seaborn\"] = True\n        \n        import sklearn\n        from sklearn.decomposition import PCA\n        dependencies[\"sklearn\"] = True\n        \n        import numpy as np\n        dependencies[\"numpy\"] = True\n        \n        # Test OptiPFair bias module\n        from optipfair.bias import visualize_bias\n        dependencies[\"optipfair_bias\"] = True\n        \n        dependencies[\"all_available\"] = all([\n            dependencies[\"matplotlib\"],\n            dependencies[\"seaborn\"], \n            dependencies[\"sklearn\"],\n            dependencies[\"numpy\"],\n            dependencies[\"optipfair_bias\"]\n        ])\n        \n        return dependencies\n        \n    except ImportError as e:\n        dependencies[\"error\"] = str(e)\n        return dependencies\n\ndef check_model_architecture(model_name):\n    \"\"\"\n    Check if model has the required architecture for bias visualization\n    \"\"\"\n    try:\n        print(\"üîÑ Loading model configuration...\")\n        config = AutoConfig.from_pretrained(model_name)\n        \n        # Initialize results\n        results = {\n            \"model_name\": model_name,\n            \"config_loaded\": True,\n            \"architecture_compatible\": False,\n            \"issues\": [],\n            \"recommendations\": [],\n            \"details\": {}\n        }\n        \n        # Extract basic info\n        results[\"details\"][\"model_type\"] = getattr(config, 'model_type', 'Unknown')\n        results[\"details\"][\"num_layers\"] = getattr(config, 'num_hidden_layers', 'N/A')\n        results[\"details\"][\"hidden_size\"] = getattr(config, 'hidden_size', 'N/A')\n        results[\"details\"][\"intermediate_size\"] = getattr(config, 'intermediate_size', 'N/A')\n        \n        print(f\"üìä Model type: {results['details']['model_type']}\")\n        print(f\"üìä Layers: {results['details']['num_layers']}\")\n        print(f\"üìä Hidden size: {results['details']['hidden_size']}\")\n        \n        return results\n        \n    except Exception as e:\n        print(f\"‚ùå Error loading model: {str(e)}\")\n        return {\n            \"model_name\": model_name,\n            \"config_loaded\": False,\n            \"error\": str(e)\n        }\n\ndef test_hook_registration(model_name):\n    \"\"\"\n    Test if we can register hooks and capture activations for bias visualization.\n    Based on OptiPFair's bias module requirements.\n    \"\"\"\n    try:\n        print(\"\\nüîç Testing hook registration and activation capture...\")\n        \n        # Load a small portion of the model\n        model = AutoModel.from_pretrained(\n            model_name,\n            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n            device_map=\"auto\" if torch.cuda.is_available() else \"cpu\",\n            trust_remote_code=True\n        )\n        \n        # Try to find the model layers - OptiPFair expects model.model.layers structure\n        layers = None\n        layer_access_method = None\n        \n        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n            layers = model.model.layers\n            layer_access_method = \"model.model.layers\"\n        elif hasattr(model, 'layers'):\n            layers = model.layers\n            layer_access_method = \"model.layers\"\n        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n            layers = model.transformer.h\n            layer_access_method = \"model.transformer.h\"\n        \n        if layers is None or len(layers) == 0:\n            return {\n                \"hook_registration\": False,\n                \"layers_found\": False,\n                \"error\": \"Could not find transformer layers\"\n            }\n        \n        # Test hook registration on first layer\n        first_layer = layers[0]\n        hook_results = {\n            \"layers_found\": True,\n            \"layer_access_method\": layer_access_method,\n            \"total_layers\": len(layers),\n            \"components_found\": {},\n            \"supported_visualizations\": [],\n            \"layer_types_available\": []\n        }\n        \n        # Test for attention component (generates attention_output_layer_N)\n        if hasattr(first_layer, 'self_attn'):\n            hook_results[\"components_found\"][\"attention\"] = True\n            hook_results[\"components_found\"][\"attention_type\"] = \"self_attn\"\n            hook_results[\"layer_types_available\"].append(\"attention_output\")\n            hook_results[\"supported_visualizations\"].extend([\n                \"attention_output: mean_diff visualizations\",\n                \"attention_output: heatmap visualizations\", \n                \"attention_output: PCA analysis\"\n            ])\n        elif hasattr(first_layer, 'attn'):\n            hook_results[\"components_found\"][\"attention\"] = True\n            hook_results[\"components_found\"][\"attention_type\"] = \"attn\"\n            hook_results[\"layer_types_available\"].append(\"attention_output\")\n            hook_results[\"supported_visualizations\"].extend([\n                \"attention_output: mean_diff visualizations\",\n                \"attention_output: heatmap visualizations\", \n                \"attention_output: PCA analysis\"\n            ])\n        else:\n            hook_results[\"components_found\"][\"attention\"] = False\n            hook_results[\"components_found\"][\"attention_type\"] = None\n        \n        # Test for MLP component (generates mlp_output_layer_N)\n        if hasattr(first_layer, 'mlp'):\n            hook_results[\"components_found\"][\"mlp\"] = True\n            hook_results[\"layer_types_available\"].append(\"mlp_output\")\n            mlp = first_layer.mlp\n            \n            # Check for GLU components (important for detailed MLP analysis)\n            if hasattr(mlp, 'gate_proj'):\n                hook_results[\"components_found\"][\"gate_proj\"] = True\n                hook_results[\"layer_types_available\"].append(\"gate_proj\")\n                hook_results[\"supported_visualizations\"].extend([\n                    \"gate_proj: mean_diff visualizations\",\n                    \"gate_proj: heatmap visualizations\"\n                ])\n            \n            if hasattr(mlp, 'up_proj'):\n                hook_results[\"components_found\"][\"up_proj\"] = True\n                hook_results[\"layer_types_available\"].append(\"up_proj\")\n                hook_results[\"supported_visualizations\"].extend([\n                    \"up_proj: mean_diff visualizations\", \n                    \"up_proj: heatmap visualizations\"\n                ])\n            \n            if hasattr(mlp, 'down_proj'):\n                hook_results[\"components_found\"][\"down_proj\"] = True\n                hook_results[\"layer_types_available\"].append(\"down_proj\")\n            \n            # Add MLP visualizations (PCA only for mlp_output, not individual projections)\n            hook_results[\"supported_visualizations\"].extend([\n                \"mlp_output: mean_diff visualizations\",\n                \"mlp_output: heatmap visualizations\",\n                \"mlp_output: PCA analysis\"\n            ])\n        else:\n            hook_results[\"components_found\"][\"mlp\"] = False\n        \n        # Test for input normalization (generates input_norm_layer_N)\n        if hasattr(first_layer, 'input_layernorm'):\n            hook_results[\"components_found\"][\"input_norm\"] = True\n            hook_results[\"layer_types_available\"].append(\"input_norm\")\n        \n        # Test actual hook registration\n        test_activations = {}\n        \n        def test_hook(name):\n            def hook(module, input, output):\n                if isinstance(output, tuple):\n                    test_activations[name] = output[0].detach().cpu()\n                else:\n                    test_activations[name] = output.detach().cpu()\n            return hook\n        \n        # Register test hooks\n        handles = []\n        if hook_results[\"components_found\"][\"attention\"]:\n            if hasattr(first_layer, 'self_attn'):\n                handles.append(first_layer.self_attn.register_forward_hook(test_hook(\"test_attention\")))\n            elif hasattr(first_layer, 'attn'):\n                handles.append(first_layer.attn.register_forward_hook(test_hook(\"test_attention\")))\n        \n        if hook_results[\"components_found\"][\"mlp\"]:\n            handles.append(first_layer.mlp.register_forward_hook(test_hook(\"test_mlp\")))\n        \n        hook_results[\"hook_registration\"] = len(handles) > 0\n        \n        # Clean up\n        for handle in handles:\n            handle.remove()\n        \n        del model\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        return hook_results\n        \n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Hook registration test failed: {str(e)}\")\n        return {\n            \"hook_registration\": False,\n            \"error\": str(e)\n        }\n\ndef test_tokenizer_compatibility(model_name):\n    \"\"\"\n    Test if tokenizer works properly for bias analysis\n    \"\"\"\n    try:\n        print(\"\\nüîç Testing tokenizer compatibility...\")\n        \n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        \n        # Test tokenization with sample bias analysis prompts from OptiPFair defaults\n        test_prompts = [\n            \"The white man walked through the neighborhood. The police officer thought he\",\n            \"The Black man walked through the neighborhood. The police officer thought he\",\n            \"The male engineer proposed a solution. The team thought it was\",\n            \"The female engineer proposed a solution. The team thought it was\"\n        ]\n        \n        tokenizer_results = {\n            \"tokenizer_loaded\": True,\n            \"pad_token_available\": tokenizer.pad_token is not None,\n            \"can_tokenize\": True,\n            \"tokenization_examples\": []\n        }\n        \n        # Test tokenization\n        for prompt in test_prompts:\n            try:\n                tokens = tokenizer.tokenize(prompt)\n                if len(tokens) == 0:\n                    tokenizer_results[\"can_tokenize\"] = False\n                    break\n                tokenizer_results[\"tokenization_examples\"].append({\n                    \"prompt\": prompt,\n                    \"tokens\": len(tokens),\n                    \"success\": True\n                })\n            except Exception as e:\n                tokenizer_results[\"can_tokenize\"] = False\n                tokenizer_results[\"tokenization_examples\"].append({\n                    \"prompt\": prompt,\n                    \"error\": str(e),\n                    \"success\": False\n                })\n                break\n        \n        return tokenizer_results\n        \n    except Exception as e:\n        return {\n            \"tokenizer_loaded\": False,\n            \"error\": str(e)\n        }\n\n# Run all compatibility checks\nprint(\"Starting compatibility analysis...\")\nprint(\"=\" * 50)\n\n# Check dependencies\nprint(\"üì¶ Checking bias visualization dependencies...\")\ndep_results = check_dependencies()\n\n# Check model architecture\narch_results = check_model_architecture(MODEL_NAME)\n\n# Test hook registration\nhook_results = test_hook_registration(MODEL_NAME)\n\n# Test tokenizer\ntokenizer_results = test_tokenizer_compatibility(MODEL_NAME)\n\nprint(\"\\n‚úÖ Compatibility analysis complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_compatibility_assessment(dep_results, arch_results, hook_results, tokenizer_results):\n",
    "    \"\"\"\n",
    "    Generate final compatibility assessment\n",
    "    \"\"\"\n",
    "    assessment = {\n",
    "        \"model_name\": arch_results.get(\"model_name\", \"Unknown\"),\n",
    "        \"compatible\": False,\n",
    "        \"compatibility_score\": 0,\n",
    "        \"supported_features\": [],\n",
    "        \"issues\": [],\n",
    "        \"recommendations\": [],\n",
    "        \"details\": {}\n",
    "    }\n",
    "    \n",
    "    # Check dependencies\n",
    "    if dep_results.get(\"all_available\", False):\n",
    "        assessment[\"compatibility_score\"] += 25\n",
    "        assessment[\"supported_features\"].append(\"‚úÖ All visualization dependencies available\")\n",
    "    else:\n",
    "        assessment[\"issues\"].append(\"‚ùå Missing visualization dependencies\")\n",
    "    \n",
    "    # Check model architecture\n",
    "    if arch_results.get(\"config_loaded\", False):\n",
    "        assessment[\"compatibility_score\"] += 25\n",
    "        assessment[\"supported_features\"].append(\"‚úÖ Model configuration loaded successfully\")\n",
    "        \n",
    "        # Check for supported model types\n",
    "        model_type = arch_results.get(\"details\", {}).get(\"model_type\", \"\").lower()\n",
    "        supported_types = [\"llama\", \"mistral\", \"gemma\", \"qwen\", \"phi\"]\n",
    "        \n",
    "        if any(supported_type in model_type for supported_type in supported_types):\n",
    "            assessment[\"supported_features\"].append(f\"‚úÖ Supported architecture: {model_type}\")\n",
    "        else:\n",
    "            assessment[\"issues\"].append(f\"‚ö†Ô∏è  Architecture '{model_type}' may have limited support\")\n",
    "    else:\n",
    "        assessment[\"issues\"].append(\"‚ùå Could not load model configuration\")\n",
    "    \n",
    "    # Check hook registration\n",
    "    if hook_results.get(\"hook_registration\", False):\n",
    "        assessment[\"compatibility_score\"] += 30\n",
    "        assessment[\"supported_features\"].append(\"‚úÖ Hook registration successful\")\n",
    "        \n",
    "        # Check specific components\n",
    "        components = hook_results.get(\"components_found\", {})\n",
    "        if components.get(\"attention\", False):\n",
    "            assessment[\"supported_features\"].append(\"‚úÖ Attention components available\")\n",
    "        if components.get(\"mlp\", False):\n",
    "            assessment[\"supported_features\"].append(\"‚úÖ MLP components available\")\n",
    "        if components.get(\"gate_proj\", False) and components.get(\"up_proj\", False):\n",
    "            assessment[\"supported_features\"].append(\"‚úÖ GLU components available\")\n",
    "    else:\n",
    "        assessment[\"issues\"].append(\"‚ùå Hook registration failed\")\n",
    "    \n",
    "    # Check tokenizer\n",
    "    if tokenizer_results.get(\"tokenizer_loaded\", False):\n",
    "        assessment[\"compatibility_score\"] += 20\n",
    "        assessment[\"supported_features\"].append(\"‚úÖ Tokenizer loaded successfully\")\n",
    "        \n",
    "        if tokenizer_results.get(\"can_tokenize\", False):\n",
    "            assessment[\"supported_features\"].append(\"‚úÖ Tokenization working\")\n",
    "    else:\n",
    "        assessment[\"issues\"].append(\"‚ùå Tokenizer loading failed\")\n",
    "    \n",
    "    # Overall compatibility\n",
    "    assessment[\"compatible\"] = assessment[\"compatibility_score\"] >= 70\n",
    "    \n",
    "    # Generate recommendations\n",
    "    if assessment[\"compatible\"]:\n",
    "        assessment[\"recommendations\"] = [\n",
    "            \"üéâ Your model is compatible with OptiPFair bias visualization!\",\n",
    "            \"üì¶ Install: pip install optipfair\",\n",
    "            \"üìì Try the basic_bias_visualization.ipynb example\",\n",
    "            \"üîó Documentation: https://github.com/peremartra/optipfair\"\n",
    "        ]\n",
    "    else:\n",
    "        assessment[\"recommendations\"] = [\n",
    "            \"‚ö†Ô∏è  Your model may have limited compatibility\",\n",
    "            \"üìß Report issues: https://github.com/peremartra/optipfair/issues\",\n",
    "            \"üìö Check supported models in documentation\"\n",
    "        ]\n",
    "    \n",
    "    # Store detailed results\n",
    "    assessment[\"details\"] = {\n",
    "        \"dependencies\": dep_results,\n",
    "        \"architecture\": arch_results,\n",
    "        \"hooks\": hook_results,\n",
    "        \"tokenizer\": tokenizer_results\n",
    "    }\n",
    "    \n",
    "    return assessment\n",
    "\n",
    "# Generate final assessment\n",
    "final_assessment = generate_compatibility_assessment(dep_results, arch_results, hook_results, tokenizer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def display_compatibility_results(assessment):\n    \"\"\"\n    Display the final compatibility results in a clean format\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"üéØ OPTIPFAIR BIAS VISUALIZATION COMPATIBILITY REPORT\")\n    print(\"=\" * 60)\n    \n    # Header\n    status_emoji = \"‚úÖ\" if assessment[\"compatible\"] else \"‚ùå\"\n    status_text = \"COMPATIBLE\" if assessment[\"compatible\"] else \"LIMITED COMPATIBILITY\"\n    \n    print(f\"\\n{status_emoji} STATUS: {status_text}\")\n    print(f\"üìä COMPATIBILITY SCORE: {assessment['compatibility_score']}/100\")\n    print(f\"üì¶ MODEL: {assessment['model_name']}\")\n    \n    # Supported features\n    if assessment[\"supported_features\"]:\n        print(f\"\\n‚úÖ SUPPORTED FEATURES:\")\n        for feature in assessment[\"supported_features\"]:\n            print(f\"   {feature}\")\n    \n    # Issues\n    if assessment[\"issues\"]:\n        print(f\"\\n‚ö†Ô∏è  ISSUES FOUND:\")\n        for issue in assessment[\"issues\"]:\n            print(f\"   {issue}\")\n    \n    # Available visualizations - Enhanced with OptiPFair manual information\n    print(f\"\\nüé® AVAILABLE VISUALIZATIONS:\")\n    if assessment[\"compatible\"]:\n        hook_details = assessment[\"details\"].get(\"hooks\", {})\n        components = hook_details.get(\"components_found\", {})\n        layer_types = hook_details.get(\"layer_types_available\", [])\n        \n        print(f\"   üìä VISUALIZATION TYPES:\")\n        \n        # Mean difference plots\n        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]):\n            print(f\"   üîç MEAN DIFFERENCE PLOTS:\")\n            for layer_type in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]:\n                if layer_type in layer_types:\n                    print(f\"      ‚Ä¢ {layer_type}_layer_N visualizations\")\n        \n        # Heatmap visualizations  \n        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]):\n            print(f\"   üî• HEATMAP VISUALIZATIONS:\")\n            for layer_type in [\"attention_output\", \"mlp_output\", \"gate_proj\", \"up_proj\"]:\n                if layer_type in layer_types:\n                    print(f\"      ‚Ä¢ {layer_type}_layer_N heatmaps\")\n        \n        # PCA analysis (only for attention_output and mlp_output)\n        if any(lt in layer_types for lt in [\"attention_output\", \"mlp_output\"]):\n            print(f\"   üìà PCA ANALYSIS:\")\n            for layer_type in [\"attention_output\", \"mlp_output\"]:\n                if layer_type in layer_types:\n                    print(f\"      ‚Ä¢ {layer_type}_layer_N PCA plots\")\n        \n        print(f\"   üìä BIAS METRICS:\")\n        print(f\"      ‚Ä¢ Quantitative bias measurements\")\n        print(f\"      ‚Ä¢ Cross-layer activation comparisons\")\n        print(f\"      ‚Ä¢ Statistical significance tests\")\n        print(f\"      ‚Ä¢ Layer-wise progression analysis\")\n    else:\n        print(\"   ‚ö†Ô∏è  Limited or no visualization support\")\n    \n    # Layer-specific capabilities based on OptiPFair documentation\n    hook_details = assessment[\"details\"].get(\"hooks\", {})\n    if hook_details.get(\"supported_visualizations\"):\n        print(f\"\\nüîç DETECTED LAYER CAPABILITIES:\")\n        for viz in hook_details[\"supported_visualizations\"]:\n            print(f\"   ‚úÖ {viz}\")\n    \n    # Layer types available\n    if hook_details.get(\"layer_types_available\"):\n        print(f\"\\nüèóÔ∏è  AVAILABLE LAYER TYPES:\")\n        for layer_type in hook_details[\"layer_types_available\"]:\n            print(f\"   ‚Ä¢ {layer_type}_layer_N (N = 0 to {hook_details.get('total_layers', 'unknown')-1})\")\n    \n    # Recommendations\n    if assessment[\"recommendations\"]:\n        print(f\"\\nüí° RECOMMENDATIONS:\")\n        for rec in assessment[\"recommendations\"]:\n            print(f\"   {rec}\")\n    \n    # Technical details\n    arch_details = assessment[\"details\"].get(\"architecture\", {}).get(\"details\", {})\n    if arch_details:\n        print(f\"\\nüîß TECHNICAL DETAILS:\")\n        print(f\"   ‚Ä¢ Model Type: {arch_details.get('model_type', 'unknown')}\")\n        print(f\"   ‚Ä¢ Layers: {arch_details.get('num_layers', 'unknown')}\")\n        print(f\"   ‚Ä¢ Hidden Size: {arch_details.get('hidden_size', 'unknown')}\")\n    \n    hook_details = assessment[\"details\"].get(\"hooks\", {})\n    if hook_details.get(\"layers_found\"):\n        print(f\"   ‚Ä¢ Layer Access: {hook_details.get('layer_access_method', 'unknown')}\")\n        print(f\"   ‚Ä¢ Total Layers: {hook_details.get('total_layers', 'unknown')}\")\n        \n        # Component availability\n        components = hook_details.get(\"components_found\", {})\n        print(f\"   ‚Ä¢ Attention Component: {'‚úÖ' if components.get('attention') else '‚ùå'}\")\n        print(f\"   ‚Ä¢ MLP Component: {'‚úÖ' if components.get('mlp') else '‚ùå'}\")\n        if components.get('mlp'):\n            print(f\"   ‚Ä¢ GLU Architecture: {'‚úÖ' if components.get('gate_proj') and components.get('up_proj') else '‚ùå'}\")\n            print(f\"   ‚Ä¢ Gate Projection: {'‚úÖ' if components.get('gate_proj') else '‚ùå'}\")\n            print(f\"   ‚Ä¢ Up Projection: {'‚úÖ' if components.get('up_proj') else '‚ùå'}\")\n            print(f\"   ‚Ä¢ Down Projection: {'‚úÖ' if components.get('down_proj') else '‚ùå'}\")\n    \n    print(\"=\" * 60)\n\n# Display final results\ndisplay_compatibility_results(final_assessment)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üîó What's Next?\n\n### ‚úÖ If your model is compatible:\n- **Install OptiPFair with bias visualization support:**\n  ```bash\n  pip install \"optipfair[viz]\"\n  ```\n- **Try basic bias visualization:**\n  ```python\n  from optipfair.bias import visualize_bias\n  # Use default prompt pairs or create custom ones\n  visualize_bias(model, tokenizer, output_dir=\"./bias_analysis\")\n  ```\n- **Explore specific visualizations:**\n  - `visualize_mean_differences()` for layer-wise analysis\n  - `visualize_heatmap()` for detailed activation patterns\n  - `visualize_pca()` for dimensional reduction analysis\n- **Custom analysis:** Create prompt pairs for your specific bias concerns\n\n### ‚ùå If your model has limited compatibility:\n- **Check layer structure:** Your model may need `model.model.layers` structure\n- **Request support:** Open an issue on [GitHub](https://github.com/peremartra/optipfair/issues)\n- **Try alternatives:** Use a supported model (LLaMA, Mistral, Gemma, Qwen, Phi) for testing\n- **Contribute:** Help us add support for your model architecture!\n\n---\n\n## üìö Learn More About OptiPFair Bias Visualization\n\n### üéØ **Key Features:**\n- **Layer Types Analyzed:** `attention_output`, `mlp_output`, `gate_proj`, `up_proj`, `down_proj`\n- **Visualization Types:** Mean differences, heatmaps, PCA analysis\n- **Metrics:** Quantitative bias measurements with statistical analysis\n- **Layer Selection:** `\"first_middle_last\"`, `\"all\"`, or specific indices\n\n### üìñ **Resources:**\n- **üìñ Documentation:** [OptipFair GitHub](https://github.com/peremartra/optipfair)  \n- **üìù LLM Reference Manual:** `optipfair_llm_reference_manual.txt` for detailed API info\n- **üéì Examples:** Check out the `examples/` directory for tutorials\n- **üî¨ Research:** \"From Biased to Balanced: Visualizing and Fixing Bias in Transformer Models\"\n\n### üõ†Ô∏è **Example Usage:**\n```python\n# Basic usage\nfrom optipfair.bias import visualize_bias\n_, metrics = visualize_bias(\n    model, tokenizer,\n    visualization_types=[\"mean_diff\", \"heatmap\", \"pca\"],\n    layers=\"first_middle_last\"\n)\n\n# Advanced - target specific layers\nfrom optipfair.bias import visualize_pca\nvisualize_pca(\n    model, tokenizer,\n    prompt_pair=(\"The white doctor...\", \"The Black doctor...\"),\n    layer_key=\"attention_output_layer_8\"  # Specific layer\n)\n```\n\n---\n\nIf you found this notebook useful, the best way to support the OptiPFair project is by **starring it on GitHub**. Your support helps boost the project's visibility and reach more developers and researchers.\n\n### ‚û°Ô∏è [**Star OptiPFair on GitHub**](https://github.com/peremartra/optipfair)\n\n---\nYou can also follow my work and new projects on:\n\n* **[LinkedIn](https://www.linkedin.com/in/pere-martra/)**\n* **[X / Twitter](https://twitter.com/PereMartra)**"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}